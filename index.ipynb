{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade --quiet pypdf chromadb pandas_gbq google bigquery google-search-results matplotlib wikipedia numexpr langchain langsmith  langchain-core langchain-community langchain-openai "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Things Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getenv('./.env')\n",
    "\n",
    "openAiApiKey = os.getenv('OPENAI_API_KEY')\n",
    "bigqueryProject = os.getenv('BIG_QUERY_PROJECT')\n",
    "bigqueryKey = os.getenv('BIG_QUERY_KEY')\n",
    "\n",
    "bigqueryKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    bigqueryKey,\n",
    ")\n",
    "\n",
    "bigquery_client = bigquery.Client(\n",
    "    project=bigqueryProject,\n",
    "    credentials=credentials\n",
    ")\n",
    "\n",
    "bigquery_schema = ''\n",
    "\n",
    "datasets = ['TrakingProviders', 'ProdReplica']\n",
    "\n",
    "## Transform the previous typescript code to python\n",
    "def get_all_tables(dataset_id):\n",
    "    try:\n",
    "        # Get the dataset\n",
    "        tables = bigquery_client.list_tables(dataset_id)\n",
    "\n",
    "        # Get all tables in the dataset\n",
    "        print(tables)\n",
    "        # Object to store table schemas\n",
    "        tableSchemas = ''\n",
    "\n",
    "        # Iterate through each table\n",
    "        for table in tables:\n",
    "            tableName = table.table_id\n",
    "\n",
    "            metadata = bigquery_client.get_table(f\"{dataset_id}.{tableName}\")\n",
    "\n",
    "            metadataFormatted = [f\"{field.name}: {field.field_type};\" for field in metadata.schema]\n",
    "\n",
    "            schemaString = f\"\"\"\n",
    "                ##########\n",
    "                TABLE {dataset_id}.{tableName} {{\n",
    "                    {metadataFormatted}\n",
    "                }}\n",
    "            \"\"\"\n",
    "\n",
    "            tableSchemas += schemaString\n",
    "\n",
    "        return tableSchemas\n",
    "    except Exception as error:\n",
    "        print('Error fetching BigQuery table schemas:', error)\n",
    "        raise error\n",
    "\n",
    "for dataset in datasets:\n",
    "    dump = get_all_tables(dataset)\n",
    "    bigquery_schema += \"########## \" + dump\n",
    "bigquery_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.agents import AgentExecutor, load_tools, ZeroShotAgent, initialize_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\", \n",
    "    api_key=openAiApiKey,\n",
    "    temperature=0\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Susep Documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "import PyPDF2\n",
    "\n",
    "## scrap the following website and find the element with the xpath //*[@id=\"content-core\"]/ul\n",
    "\n",
    "\n",
    "susep_documents = \"\"\n",
    "data = [\n",
    "    {\n",
    "        \"url\": \"https://www.gov.br/susep/pt-br/assuntos/meu-futuro-seguro/seguros-previdencia-e-capitalizacao/seguros/seguro-de-automoveis\",\n",
    "        \"xpath\": \"/html/body/div[2]/div[1]/main/div[2]/div\"\n",
    "    },\n",
    "    # {\n",
    "    #     \"url\": \"https://www.gov.br/susep/pt-br/planos-e-produtos/seguros/seguro-de-automoveis\",\n",
    "    #     \"xpath\": \"/html/body/div[2]/div[1]/main/div[2]/div/div[4]/ul\"\n",
    "    # },\n",
    "    {\n",
    "        \"url\": 'https://www.gov.br/susep/pt-br/planos-e-produtos/seguros/seguro-compreensivo',\n",
    "        \"xpath\": '/html/body/div[2]/div[1]/main/div[2]/div/div[4]/ul'\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://www.gov.br/susep/pt-br/planos-e-produtos/seguros/seguro-de-responsabilidade\",\n",
    "        \"xpath\": \"/html/body/div[2]/div[1]/main/div[2]/div/div[4]/ul\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://www.gov.br/susep/pt-br/planos-e-produtos/seguros/seguro-de-pessoas\",\n",
    "        \"xpath\": \"/html/body/div[2]/div[1]/main/div[2]/div\"\n",
    "    },\n",
    "    {\n",
    "        \"url\":\"https://www.gov.br/susep/pt-br/planos-e-produtos/seguros/subitens-fora-do-menu/perguntas-e-respostas-seguro-de-pessoas-com-cobertura-de-sobrevivencia\",\n",
    "        \"xpath\":\"/html/body/div[2]/div[1]/main/div[2]/div/div[4]/ul\"\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://www.gov.br/susep/pt-br/planos-e-produtos/seguros/seguro-de-danos\",\n",
    "        \"xpath\": \"/html/body/div[2]/div[1]/main/div[2]/div\"\n",
    "    },\n",
    "]\n",
    "\n",
    "for d in data:\n",
    "    page = requests.get(d[\"url\"])\n",
    "    tree = html.fromstring(page.content)\n",
    "    element = tree.xpath(d[\"xpath\"])\n",
    "    susep_documents += \"#######\" + element[0].text_content()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Susep Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, \n",
    "    chunk_overlap=50, \n",
    "    separators=[\"#######\", \"\\n\", \"\\r\\n\", \"\\r\"],\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(susep_documents)\n",
    "documents = text_splitter.create_documents(texts)\n",
    "print(len(documents))\n",
    "db = Chroma.from_documents(documents, OpenAIEmbeddings(\n",
    "    api_key=openAiApiKey,\n",
    "))\n",
    "\n",
    "susep_retriever = db.as_retriever()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Brick CG Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=0,\n",
    "    separators=[\"Página\"],\n",
    ")\n",
    "\n",
    "pdf_file = open(\"./brick_bs_cg.pdf\", \"rb\")\n",
    "pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "pdf_text = \"\"\n",
    "for page in pdf_reader.pages:\n",
    "    pdf_text += page.extract_text()\n",
    "pdf_file.close()\n",
    "\n",
    "\n",
    "\n",
    "texts = text_splitter.split_text(pdf_text)\n",
    "# print(texts)\n",
    "documents = text_splitter.create_documents(texts)\n",
    "# print(documents)\n",
    "\n",
    "brick_cg_db = Chroma.from_documents(documents, OpenAIEmbeddings(\n",
    "    # model=\"gpt-3.5-turbo\", \n",
    "    api_key=openAiApiKey,\n",
    "))\n",
    "\n",
    "brick_cg_retriever = brick_cg_db.as_retriever(\n",
    "    search_kwargs={\"k\": 5, \"lambda_mult\": 0.25},\n",
    "    search_type=\"mmr\",\n",
    ")\n",
    "\n",
    "brick_cg_retriever.get_relevant_documents(\"A apólice cobre danos materiais a terceiros?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "@tool\n",
    "def read_and_stringify_csv_file(file_path): \n",
    "    \"\"\"This function reads a csv file and returns a stringified version of the data\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "            data = list(csv_reader)\n",
    "            print(data)\n",
    "        return {\"file_path\": file_path, \"data\": str(data[0:100]),}\n",
    "    except Exception as error:\n",
    "        return {\"error\": str(error)}\n",
    "\n",
    "@tool\n",
    "def read_and_stringify_xlsx_file(file_path):\n",
    "    \"\"\"This function reads an xlsx file and returns a stringified version of the data\"\"\"\n",
    "    try:\n",
    "        data = pd.read_excel(file_path)\n",
    "        return {\"file_path\": file_path, \"data\": str(data[0:100])}\n",
    "    except Exception as error:\n",
    "        return {\"error\": str(error)}\n",
    "\n",
    "@tool\n",
    "def read_and_stringify_txt_file(file_path):\n",
    "    \"\"\"This function reads a txt file and returns a stringified version of the data\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = file.read()\n",
    "        return {\"data\": str(data[0:100]),  \"file_path\": file_path}\n",
    "    except Exception as error:\n",
    "        return {\"error\": str(error)}\n",
    "\n",
    "\n",
    "@tool\n",
    "def read_and_stringify_json_file(file_path):\n",
    "    \"\"\"This function reads a json file and returns a stringified version of the data\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return {\"file_path\": file_path, \"data\": str(data[0:100])}\n",
    "    except Exception as error:\n",
    "        return {\"error\": str(error)}\n",
    "\n",
    "def translate_to_portuguese(text):\n",
    "    \"\"\"This function translates a text to portuguese\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "       (\"user\", \"\"\"\n",
    "            Resume the following and translate it to portuguese: text:{text}.\n",
    "            Não de introdução e conclusão.\n",
    "            Apenas retorne o texto traduzido.\n",
    "            \"\"\"),\n",
    "    )\n",
    "    \n",
    "\n",
    "    chain = (\n",
    "        prompt |\n",
    "        model\n",
    "    )\n",
    "    res = chain.invoke({\"text\": text})\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def query_database(query):\n",
    "    df = bigquery_client.query(query).to_dataframe()\n",
    "\n",
    "    return df\n",
    "\n",
    "@tool\n",
    "def query_database_chain(question):\n",
    "    \"\"\"This function queries the database with a given question\"\"\"\n",
    "    try:\n",
    "        sql_base_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"\n",
    "                You are a backend developer specialized in writting Google BigQuery SQL queries.\n",
    "                Return only the SQL query that you should use to retrieve the data from the database.\n",
    "                You should be able to generate the best SQL query to retrieve the data from the database.\n",
    "                The data that you should retrieve is related to the input that you will receive\n",
    "                Try to return the fewest columns as possible. Merge columns if necessary.\n",
    "                Base on these database schema to generate the best SQL query:\n",
    "                {context}\n",
    "            \"\"\"),\n",
    "            (\"user\", \"\"\"\n",
    "                Generate a query for: {input}\n",
    "            \"\"\")\n",
    "        ])\n",
    "\n",
    "        def format_sql(sql):\n",
    "            return sql.replace('\"', '').replace('\\\\n', ' ').replace('\\\\t', ' ').replace('```sql', '').replace('```', '').strip()\n",
    "        \n",
    "        sql_parser = StrOutputParser().pipe(format_sql)\n",
    "\n",
    "        validation_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"\n",
    "                You are a SQL expert. \n",
    "                You are a Google BigQuery SQL master.\n",
    "                You know everything about the SQL sintax of Google BigQuery.\n",
    "                You are very good at verifying SQL queries and making them better.\n",
    "\n",
    "                When you see a SQL query be carefult about the following:\n",
    "                - Check date functions sintax.\n",
    "                    -- Examples:   \n",
    "                        --- DATE_ADD(date_expression, INTERVAL int64_expression date_part). date_part must be one off: DAY, WEEK, MONTH, QUARTER, YEAR.\n",
    "                        --- DATE_DIFF(date_expression_a, date_expression_b, date_part). date_part must be one off: DAY, WEEK, MONTH, QUARTER, YEAR.\n",
    "                        --- DATE_SUB(date_expression, INTERVAL int64_expression date_part). date_part must be one off: DAY, WEEK, MONTH, QUARTER, YEAR.\n",
    "                        --- DATE_TRUNC(date_expression, date_part).  date_part must be one off: DAY, WEEK, MONTH, QUARTER, YEAR.\n",
    "                        --- EXTRACT(date_part FROM date_expression). date_part must be one off: DAYOFWEEK, DAY, DAYOFYEAR, WEEK, MONTH, QUARTER, YEAR.\n",
    "                        --- FORMAT_DATE(date_expression, format_string). format_string must be made off: %Y, %m, %d, %H, %M, %S.\n",
    "                        --- PARSE_DATE(format_string, date_string). format_string must be made off: %Y, %m, %d, %H, %M, %S.\n",
    "                        --- TIMESTAMP_ADD(timestamp_expression, INTERVAL int64_expression date_part). date_part must be one off: MICROSECOND, MILLISECOND, SECOND, MINUTE, HOUR, DAY, WEEK, MONTH, QUARTER, YEAR.\n",
    "                        --- TIMESTAMP_DIFF(timestamp_expression_a, timestamp_expression_b, date_part). date_part must be one off: MICROSECOND, MILLISECOND, SECOND, MINUTE, HOUR, DAY, WEEK, MONTH, QUARTER, YEAR.\n",
    "                        --- TIMESTAMP_SUB(timestamp_expression, INTERVAL int64_expression date_part). date_part must be one off: MICROSECOND, MILLISECOND, SECOND, MINUTE, HOUR, DAY, WEEK, MONTH, QUARTER, YEAR.\n",
    "                        --- TIMESTAMP_TRUNC(timestamp_expression, date_part). date_part must be one off: MICROSECOND, MILLISECOND, SECOND, MINUTE, HOUR, DAY, WEEK, MONTH, QUARTER, YEAR.\n",
    "                        --- DATETIME_ADD(datetime_expression, INTERVAL int64_expression date_part). date_part must be one off: MICROSECOND, MILLISECOND, SECOND, MINUTE, HOUR, DAY, WEEK, MONTH, QUARTER, YEAR.\n",
    "                        --- DATETIME_SUB(datetime_expression, INTERVAL int64_expression date_part). date_part must be one off: MICROSECOND, MILLISECOND, SECOND, MINUTE, HOUR, DAY, WEEK, MONTH, QUARTER, YEAR.\n",
    "                        --- DATETIME_TRUNC(datetime_expression, date_part). date_part must be one off: MICROSECOND, MILLISECOND, SECOND, MINUTE, HOUR, DAY, WEEK, MONTH, QUARTER, YEAR.\n",
    "                Return only the SQL query that should be use to retrieve the data from the database.\n",
    "                Do not give introduction or conclusion. Answer with only the SQL query.\n",
    "                Validate this SQL: {result}\n",
    "            \"\"\")\n",
    "        ])\n",
    "            \n",
    "\n",
    "        chain = (\n",
    "            sql_base_prompt |\n",
    "            model |\n",
    "            {\"result\": sql_parser} |\n",
    "            validation_prompt |\n",
    "            model |\n",
    "            sql_parser |\n",
    "            query_database\n",
    "        )\n",
    "\n",
    "        res = chain.invoke({\"input\": question, \"context\": bigquery_schema}) \n",
    "\n",
    "        return res\n",
    "    except Exception as error:\n",
    "        return {\"error\": str(error)}\n",
    "# query_database_chain(\"Quais placas andaram mais rápido no mês de fevereiro de 2024?\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def convert_to_json_format(text):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [(\"system\", \"\"\"\n",
    "            You are a backend developer specialized in converting text to JSON format.\n",
    "            You are very good at converting text to JSON format.\n",
    "            You are very good at identifying keys in a text imagining that it would be plot into a graph.\n",
    "            You divide the data into two keys:\n",
    "                - x: The x values of the graph.\n",
    "                - y: The y values of the graph.\n",
    "            You do not give introduction or conclusion. Answer with only the JSON format.\n",
    "         \"\"\"),\n",
    "         (\"user\", \"\"\"\n",
    "            Convert the following text to a JSON format.\n",
    "            text={text}  \n",
    "            \"\"\")]\n",
    "     )\n",
    "    \n",
    "    chain = (\n",
    "        prompt |\n",
    "        model |\n",
    "        JsonOutputParser()\n",
    "    )\n",
    "\n",
    "    res = chain.invoke({\"text\": text})\n",
    "\n",
    "    return res\n",
    "\n",
    "@tool\n",
    "def plot_line_chart(data):\n",
    "    \"\"\"This function receives a dictionary with x and y values and plots a line chart\"\"\"\n",
    "\n",
    "    try:\n",
    "        json = convert_to_json_format(data)\n",
    "\n",
    "\n",
    "        # return {\"data_type\": type(json), \"data\": str(json)}\n",
    "        x = np.array(json['x'])\n",
    "        y = np.array(json['y'])\n",
    "        \n",
    "        # plt.xticks(np.arange(0, len(json['x']), step=10), json['x'][::10])\n",
    "        # plt.yticks(np.arange(0, len(json['y']), step=10), json['y'][::10])\n",
    "\n",
    "        plt.plot(x, y)\n",
    "        plt.show()\n",
    "        return {\"data\": \"Line chart plotted\"}\n",
    "    except Exception as error:\n",
    "        return {\"error\": str(error), \"message\": \"Try to solve the problem and run the tool again. If needed, query the database for the data again.\"}\n",
    "\n",
    "@tool\n",
    "def plot_bar_chart(data):\n",
    "    \"\"\"This function receives a dictionary with x and y values and plots a bar chart\"\"\"\n",
    "\n",
    "    try:\n",
    "        json = convert_to_json_format(data)\n",
    "\n",
    "\n",
    "        # return {\"data_type\": type(json), \"data\": str(json)}\n",
    "        x = np.array(json['x'])\n",
    "        y = np.array(json['y'])\n",
    "        \n",
    "        # plt.xticks(np.arange(0, len(json['x']), step=10), json['x'][::10])\n",
    "        # plt.yticks(np.arange(0, len(json['y']), step=10), json['y'][::10])\n",
    "\n",
    "        plt.bar(x, y)\n",
    "        plt.show()\n",
    "        return {\"data\": \"Bar chart plotted\"}\n",
    "    except Exception as error:\n",
    "        return {\"error\": str(error), \"message\": \"Try to solve the problem and run the tool again. If needed, query the database for the data again.\"}\n",
    "\n",
    "@tool\n",
    "def plot_pie_chart(data):\n",
    "    \"\"\"This function receives a dictionary with x and y values and plots a pie chart\"\"\"\n",
    "\n",
    "    try:\n",
    "        json = convert_to_json_format(data)\n",
    "\n",
    "        float_y = [float(i) for i in json['y']]\n",
    "        # return {\"data_type\": type(json), \"data\": str(json)}\n",
    "        x = np.array(json['x'])\n",
    "        y = np.array(float_y)\n",
    "        \n",
    "        # plt.xticks(np.arange(0, len(json['x']), step=10), json['x'][::10])\n",
    "        # plt.yticks(np.arange(0, len(json['y']), step=10), json['y'][::10])\n",
    "\n",
    "        plt.pie(y, labels=x, autopct='%1.1f%%')\n",
    "        plt.show()\n",
    "        return {\"data\": \"Pie chart plotted\"}\n",
    "    except Exception as error:\n",
    "        return {\"error\": str(error), \"message\": \"Try to solve the problem and run the tool again. If needed, query the database for the data again.\"}\n",
    "\n",
    "# @tool\n",
    "# def plot_histogram(data):\n",
    "#     \"\"\"This function receives a dictionary with x values and plots a histogram chart\"\"\"\n",
    "\n",
    "#     try:\n",
    "#         json = convert_to_json_format(data)\n",
    "\n",
    "#         # return {\"data_type\": type(json), \"data\": str(json)}\n",
    "#         x = np.array(json['x'])\n",
    "        \n",
    "#         # plt.xticks(np.arange(0, len(json['x']), step=10), json['x'][::10])\n",
    "#         # plt.yticks(np.arange(0, len(json['y']), step=10), json['y'][::10])\n",
    "\n",
    "#         plt.hist(x, bins=10)\n",
    "#         plt.show()\n",
    "#         return {\"data\": \"Histogram chart plotted\"}\n",
    "#     except Exception as error:\n",
    "#         return {\"error\": str(error), \"message\": \"Try to solve the problem and run the tool again. If needed, query the database for the data again.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insurance RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "def get_susep_relevant_documents(question):\n",
    "    try:\n",
    "        content = \"\"\n",
    "        documents = susep_retriever.get_relevant_documents(question)\n",
    "        for document in documents:\n",
    "            content += document.page_content\n",
    "        return content\n",
    "    \n",
    "    except Exception as error:\n",
    "        return {\"error\": str(error)}\n",
    "    \n",
    "def audit(data):\n",
    "    print(data)\n",
    "    return data\n",
    "\n",
    "@tool\n",
    "def susep_helper(question):\n",
    "    \"\"\"This function queries the SUSEP documents with a given question to answer insurance related questions.\"\"\"\n",
    "    try:\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", \"\"\"\n",
    "                    SUSEP is the Brazilian insurance regulatory agency.\n",
    "                    You are an insurance agent specialized in SUSEP documents.\n",
    "                    You are very good at finding information in SUSEP documents.\n",
    "                    You are very good at generating the best response to insurance related questions.\n",
    "                    Answer it using the following context:\n",
    "                    {context}\n",
    "                 \"\"\"),\n",
    "                (\"user\", \"\"\"\n",
    "                Answer this question as best as you can: {question}\n",
    "            \"\"\")]\n",
    "        )\n",
    "\n",
    "        chain = (\n",
    "            {\"context\": itemgetter(\"question\") | susep_retriever,\"question\": itemgetter(\"question\")} \n",
    "            | prompt \n",
    "            | model \n",
    "        )\n",
    "\n",
    "        res = chain.invoke({\"question\": question})\n",
    "\n",
    "        return res.content\n",
    "        \n",
    "    except Exception as error:\n",
    "        return {\"error\": str(error)}\n",
    "susep_helper(\"O que é um seguro de APP?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brick CG RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "@tool\n",
    "def brick_cg_helper(question):\n",
    "    \"\"\"This function queries the Brick Seguros documents with a given question to answer insurance related questions related to Brick Seguros.\"\"\"\n",
    "    try:\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", \"\"\"\n",
    "                    Brick Seguros is a Brazilian insurance company that you work for.\n",
    "                    You are an insurance agent specialized in understanding Brick Seguros insurance terms.\n",
    "                    You are very good at finding information in Brick Seguros documents.\n",
    "                    You are very good at generating the best response to insurance related questions.\n",
    "                    {context}\n",
    "                 \"\"\"),\n",
    "                (\"user\", \"\"\"\n",
    "                Answer this question as best as you can: {question}\n",
    "            \"\"\")]\n",
    "        )\n",
    "\n",
    "        chain = (\n",
    "            {\"context\": itemgetter(\"question\") | brick_cg_retriever,\"question\": itemgetter(\"question\")} \n",
    "            | prompt \n",
    "            | model \n",
    "        )\n",
    "\n",
    "        res = chain.invoke({\"question\": question})\n",
    "\n",
    "        return res.content\n",
    "        \n",
    "    except Exception as error:\n",
    "        return {\"error\": str(error)}\n",
    "# susep_helper(\"O que é um seguro de APP?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quoting Insurance Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_reader_agent = initialize_agent(\n",
    "    agent_name=\"file_reader_agent\",\n",
    "    tools=[read_and_stringify_csv_file, read_and_stringify_xlsx_file, read_and_stringify_txt_file, read_and_stringify_json_file],\n",
    "    llm=model\n",
    ")\n",
    "\n",
    "\n",
    "def read_and_stringify_file(file_path):\n",
    "    return file_reader_agent.run(file_path)\n",
    "\n",
    "\n",
    "def generate_script_from_file(data):\n",
    "    \"\"\"\n",
    "    This function generates a python script to transform the data into a pandas dataframe.\n",
    "    It should always run before quoting vehicle data.\n",
    "    \"\"\"\n",
    "    translation_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"\"\"\n",
    "            Você é especialista em identificar a chave de campos desejados em um dataset. \n",
    "            Você é muito bom em escrever jsons.\n",
    "            Não escreva nenhuma introdução ou conclusão.\n",
    "            Retorne apenas o json que mapeia os campos do dataset para as chaves desejadas.\n",
    "            \"\"\"),\n",
    "            (\"user\", \"\"\"\n",
    "            Gere um json que mapeie os campos do dataset para as chaves desejadas.:\n",
    "            \n",
    "            --\n",
    "            Schema: \n",
    "                - plate: $PLATE_ATTRIBUTE_KEY\n",
    "                - make: $MAKE_ATTRIBUTE_KEY\n",
    "                - model: $MODEL_ATTRIBUTE_KEY\n",
    "                - year: $YEAR_ATTRIBUTE_KEY\n",
    "\n",
    "            --\n",
    "            Dataset recebidos: {data}\n",
    "            \"\"\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = (\n",
    "        translation_prompt\n",
    "        | model\n",
    "        | JsonOutputParser()\n",
    "    )\n",
    "\n",
    "    return chain.invoke({\"data\": data})\n",
    "    \n",
    "@tool\n",
    "def quote_vehicles(file_path):\n",
    "    \"\"\"\n",
    "        This function is used to quote vehicles. It receives a file with the content of the vehicles and returns a list of quotes.\n",
    "    \"\"\"\n",
    "    \n",
    "    try: \n",
    "        file_path_ref = \"\"\n",
    "        \n",
    "        file_path_arr = file_path.split(\"= \")\n",
    "        if(len(file_path_arr) > 1):\n",
    "            file_path_ref = file_path_arr[1].replace('\"', \"\").strip()\n",
    "        else:\n",
    "            file_path_ref = file_path\n",
    "\n",
    "        file_content = read_and_stringify_file(file_path_ref)\n",
    "\n",
    "        attr_map = generate_script_from_file(file_content)\n",
    "        print(attr_map)\n",
    "\n",
    "        file_extension = file_path_ref.split(\".\")[-1]\n",
    "\n",
    "        vehicles = []\n",
    "        if file_extension == \"json\":\n",
    "            content = {}\n",
    "            with open(file_path_ref, 'r') as file:\n",
    "                content = json.load(file)\n",
    "                \n",
    "                for vehicle in content:\n",
    "                    vehicles.append({\n",
    "                        \"plate\": vehicle[attr_map[\"plate\"]],\n",
    "                        \"make\": vehicle[attr_map[\"make\"]],\n",
    "                        \"model\": vehicle[attr_map[\"model\"]],\n",
    "                        \"year\": vehicle[attr_map[\"year\"]],\n",
    "                    })\n",
    "        if file_extension == \"csv\":\n",
    "            content = pd.read_csv(file_path_ref)\n",
    "            print(content)\n",
    "            for index, row in content.iterrows():\n",
    "                vehicles.append({\n",
    "                    \"plate\": row[attr_map[\"plate\"]],\n",
    "                    \"make\": row[attr_map[\"make\"]],\n",
    "                    \"model\": row[attr_map[\"model\"]],\n",
    "                    \"year\": row[attr_map[\"year\"]],\n",
    "                })\n",
    "            \n",
    "        print(vehicles)\n",
    "        \n",
    "        quotes = []\n",
    "        \n",
    "        for vehicle in vehicles:\n",
    "            price = 1000\n",
    "\n",
    "            if int(vehicle[\"year\"]) < 2020:\n",
    "                price += 500\n",
    "\n",
    "            quotes.append({\n",
    "                \"plate\": vehicle[\"plate\"],\n",
    "                \"make\": vehicle[\"make\"],\n",
    "                \"model\": vehicle[\"model\"],\n",
    "                \"year\": vehicle[\"year\"],\n",
    "                \"price\": price\n",
    "            })\n",
    "\n",
    "        return quotes\n",
    "    except Exception as error:\n",
    "        return {\"error\": str(error), \"message\": \"Make sure you are only passing the file address as a parameter.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Issuance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool\n",
    "def issue_policy(data):\n",
    "    \"\"\"\n",
    "    This function receives a list of quotes and issues a policy for them.\n",
    "    \"\"\"\n",
    "\n",
    "    return \"Policy issued for the following vehicles: \" + str(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_tools = load_tools([\"wikipedia\", \"serpapi\", \"llm-math\"], from_llm=model, llm=model)\n",
    "tools = [\n",
    "    read_and_stringify_csv_file,\n",
    "    read_and_stringify_xlsx_file,\n",
    "    read_and_stringify_txt_file,\n",
    "    read_and_stringify_json_file,\n",
    "    plot_line_chart,\n",
    "    plot_bar_chart,\n",
    "    plot_pie_chart,\n",
    "    issue_policy,\n",
    "    susep_helper,\n",
    "    brick_cg_helper,\n",
    "    # plot_histogram,\n",
    "    query_database_chain,\n",
    "    quote_vehicles,\n",
    "    loaded_tools[0],\n",
    "    loaded_tools[1],\n",
    "    loaded_tools[2]\n",
    "]\n",
    "\n",
    "prefix = \"\"\"Have a conversation with a human answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "llm_chain = LLMChain(llm=model, prompt=prompt)\n",
    "\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, \n",
    "    tools=tools, \n",
    "    verbose=True, \n",
    "    memory=memory,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# log the prompt from agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f'\"Have a conversation with a human answering the following questions as best you can. You have access to the following tools:\\n\\nread_and_stringify_csv_file: read_and_stringify_csv_file(file_path) - This function reads a csv file and returns a stringified version of the data\\nread_and_stringify_xlsx_file: read_and_stringify_xlsx_file(file_path) - This function reads an xlsx file and returns a stringified version of the data\\nread_and_stringify_txt_file: read_and_stringify_txt_file(file_path) - This function reads a txt file and returns a stringified version of the data\\nread_and_stringify_json_file: read_and_stringify_json_file(file_path) - This function reads a json file and returns a stringified version of the data\\nplot_line_chart: plot_line_chart(data) - This function plots a line chart\\nplot_bar_chart: plot_bar_chart(data) - This function plots a bar chart\\nplot_pie_chart: plot_pie_chart(data) - This function plots a pie chart\\nplot_histogram: plot_histogram(data) - This function plots a histogram\\nquote_vehicles: quote_vehicles(file_path) - This function is used to quote vehicles. It receives a file with the content of the vehicles and returns a list of quotes.\\nwikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\nSearch: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\\nCalculator: Useful for when you need to answer questions about math.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [read_and_stringify_csv_file, read_and_stringify_xlsx_file, read_and_stringify_txt_file, read_and_stringify_json_file, plot_line_chart, plot_bar_chart, plot_pie_chart, plot_histogram, quote_vehicles, wikipedia, Search, Calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\"\\n\\n{chat_history}\\nQuestion: {input}\\n{agent_scratchpad}'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrickAi:\n",
    "    def __init__(self, agent_chain):\n",
    "        self.agent_chain = agent_chain\n",
    "\n",
    "    def run(self, input):\n",
    "        content = self.agent_chain.run(input)\n",
    "        res = translate_to_portuguese(str(content))\n",
    "        return res.content\n",
    "    \n",
    "brick_ai = BrickAi(agent_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia and Google Search Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brick_ai.run(\"O que é o teorema do limite central?\")\n",
    "\n",
    "# brick_ai.run(\"O que são goroutines em Go?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brick_ai.run(\"Qual é o conteúdo de ./test_json.json\")\n",
    "\n",
    "# brick_ai.run(\"Qual é o conteúdo de ./plates.csv\")\n",
    "\n",
    "# brick_ai.run(\"Qual é o conteúdo de ./plates.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Queries Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brick_ai.run(input=\"\"\"Quantas empresas entraram no mês de janeiro de 2024?\"\"\")\n",
    "\n",
    "# brick_ai.run(input=\"\"\"Quais as 3 placas que andaram mais rápido no mês de fevereiro de 2024?\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Generation Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brick_ai.run(input=\"\"\"Use os dados do banco de dados e Gere um gráfico de linhas do número de empresas que entraram por mês em 2024\"\"\")\n",
    "\n",
    "# brick_ai.run(input=\"\"\"Gere um gráfico de barras da variação de odômetro dos 3 carros que mais rodaram em 2024\"\"\")\n",
    "\n",
    "# brick_ai.run(input=\"\"\"Gere um gráfico de pizza do número de empresas por categoria\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Insurance Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brick_ai.run(input=\"\"\"A partir de quando a cobertura de APP começa a valer?\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brick CG Related Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brick_ai.run(input=\"\"\"O sinistro é pode ser cobrado por kilometro??\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insurance Quoting Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brick_ai.run(\"Qual a diferença entre uma Apólice e um Endosso?\")\n",
    "\n",
    "# brick_ai.run(\"Faça uma cotação para os veículos no arquivo ./plates.json\")\n",
    "\n",
    "# brick_ai.run(\"Faça uma cotação para os veículos no arquivo ./plates.csv\")\n",
    "\n",
    "# brick_ai.run(\"Quanto deu a última cotação?\")\n",
    "\n",
    "# brick_ai.run(\"Quanto deu a primeira cotação?\")\n",
    "\n",
    "# brick_ai.run(\"Emita a apólice para essa última cotação. Depois me diga quanto ficou o total\")\n",
    "\n",
    "# brick_ai.run(\"Quanto deu a primeira cotação mesmo?\")\n",
    "\n",
    "# brick_ai.run(\"Quanto deu a cotação que você emitiu?\")\n",
    "\n",
    "# brick_ai.run(\"O que é cobertura de terceiros na cotação?\")\n",
    "\n",
    "# brick_ai.run(\"Quando pode ser que eu precise usar o pdf da minha apólice?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
